{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPQ6x7F3kt4UZcqQJAYZQ20"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"49a990c0470b40e9895eb427e70cbc4f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ce49e6ab81845a1aed5f31b253f627e","IPY_MODEL_06c75b5a01c94dfd9a614219d03fec25","IPY_MODEL_b223170aab9d475887e218612a07e352"],"layout":"IPY_MODEL_68ccdf4b21d34a3eb9463d422c2af514"}},"8ce49e6ab81845a1aed5f31b253f627e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3602892648c4381a20d4e9ee083a08f","placeholder":"​","style":"IPY_MODEL_0181301fcee74672a7b31c81575f231f","value":"Downloading pytorch_model.bin: 100%"}},"06c75b5a01c94dfd9a614219d03fec25":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1f6d2c7761f4a418ccdf5abae5f5931","max":548118077,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c70e2a3b00bd4ed1bf5315617687c582","value":548118077}},"b223170aab9d475887e218612a07e352":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b5321028d0c496f9747b4e7c943f721","placeholder":"​","style":"IPY_MODEL_9c2d36db68b343b2a7ab02fa34a7d7e7","value":" 548M/548M [00:01&lt;00:00, 461MB/s]"}},"68ccdf4b21d34a3eb9463d422c2af514":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3602892648c4381a20d4e9ee083a08f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0181301fcee74672a7b31c81575f231f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1f6d2c7761f4a418ccdf5abae5f5931":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c70e2a3b00bd4ed1bf5315617687c582":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b5321028d0c496f9747b4e7c943f721":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c2d36db68b343b2a7ab02fa34a7d7e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"accea588eef24b238bf8fb51d02e0785":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb499f976dc04eb48167373ca5cac62b","IPY_MODEL_8155caa6d6484101bc584a7b16805f6f","IPY_MODEL_f7cdf3600cca4a9cad476152b0ff495a"],"layout":"IPY_MODEL_46982cccf6194766a75cd7f89e67547a"}},"cb499f976dc04eb48167373ca5cac62b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03021e20aadc43a3ab5ad12ed2f796b3","placeholder":"​","style":"IPY_MODEL_ddfa552ae0ef4375b48e3466c654e70d","value":"Downloading (…)neration_config.json: 100%"}},"8155caa6d6484101bc584a7b16805f6f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_87d93aacf004431a81037253d76716fb","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce91bd5e5f8c4e0183867d87d6834218","value":124}},"f7cdf3600cca4a9cad476152b0ff495a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_869b42ebfa1846feb2edc997272d8f97","placeholder":"​","style":"IPY_MODEL_5f8e3099a1dc4d0eaf1ea73b276d1582","value":" 124/124 [00:00&lt;00:00, 6.76kB/s]"}},"46982cccf6194766a75cd7f89e67547a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03021e20aadc43a3ab5ad12ed2f796b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddfa552ae0ef4375b48e3466c654e70d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87d93aacf004431a81037253d76716fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce91bd5e5f8c4e0183867d87d6834218":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"869b42ebfa1846feb2edc997272d8f97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f8e3099a1dc4d0eaf1ea73b276d1582":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-meLtamqNOzT","executionInfo":{"status":"ok","timestamp":1680933714117,"user_tz":-480,"elapsed":18639,"user":{"displayName":"yuncong li","userId":"08224369488617466670"}},"outputId":"17b6026b-2cca-4987-de9f-c0e3e9261d3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install -r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QvNXqYKFNwUU","executionInfo":{"status":"ok","timestamp":1680930446946,"user_tz":-480,"elapsed":72949,"user":{"displayName":"yuncong li","userId":"08224369488617466670"}},"outputId":"ac9d6d9f-b7c2-48f1-97a6-c7dad870812b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/huggingface/peft.git (from -r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 9))\n","  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-np6k8885\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-np6k8885\n","  Resolved https://github.com/huggingface/peft.git to commit 0422df466e80c9b15280e34b6e2cd0ee6f68060b\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting git+https://github.com/huggingface/transformers.git (from -r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 10))\n","  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-y5v8plxh\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-y5v8plxh\n","  Resolved https://github.com/huggingface/transformers.git to commit 656e869a4523f6a0ce90b3aacbb05cc8fb5794bb\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting accelerate\n","  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: appdirs in /usr/local/lib/python3.9/dist-packages (from -r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 2)) (1.4.4)\n","Collecting loralib\n","  Downloading loralib-0.1.1-py3-none-any.whl (8.8 kB)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.37.2-py3-none-any.whl (84.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting black\n","  Downloading black-23.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets\n","  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 KB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fire\n","  Downloading fire-0.5.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gradio\n","  Downloading gradio-3.24.1-py3-none-any.whl (15.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 1)) (5.9.4)\n","Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from accelerate->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 1)) (2.0.0+cu118)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from accelerate->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 1)) (1.22.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 1)) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 1)) (23.0)\n","Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.9/dist-packages (from black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (3.2.0)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (2.0.1)\n","Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (4.5.0)\n","Collecting mypy-extensions>=0.4.3\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (8.1.3)\n","Collecting pathspec>=0.9.0\n","  Downloading pathspec-0.11.1-py3-none-any.whl (29 kB)\n","Requirement already satisfied: ipython>=7.8.0 in /usr/local/lib/python3.9/dist-packages (from black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (7.34.0)\n","Collecting tokenize-rt>=3.2.0\n","  Downloading tokenize_rt-5.0.0-py2.py3-none-any.whl (5.8 kB)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 7)) (1.4.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 7)) (2.27.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 7)) (2023.3.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 7)) (9.0.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 KB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 7)) (4.65.0)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from fire->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 8)) (1.16.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from fire->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 8)) (2.2.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 10)) (3.10.7)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 10)) (2022.10.31)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (3.7.1)\n","Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (4.2.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (3.1.2)\n","Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (2.2.0)\n","Collecting httpx\n","  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpy\n","  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting semantic-version\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting websockets>=10.0\n","  Downloading websockets-11.0.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.5/129.5 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (8.4.0)\n","Collecting gradio-client>=0.0.5\n","  Downloading gradio_client-0.0.8-py3-none-any.whl (20 kB)\n","Collecting uvicorn\n","  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles\n","  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n","Collecting fastapi\n","  Downloading fastapi-0.95.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mdit-py-plugins<=0.3.3\n","  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson\n","  Downloading orjson-3.8.9-cp39-cp39-manylinux_2_28_x86_64.whl (144 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.1/144.1 KB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-multipart\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Requirement already satisfied: markupsafe in /usr/local/lib/python3.9/dist-packages (from gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (2.1.2)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.9/dist-packages (from gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (1.10.7)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (4.3.3)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (0.4)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (0.12.0)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 7)) (2.0.12)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 7)) (22.2.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (5.7.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (4.4.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (0.2.0)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (3.0.38)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (2.14.0)\n","Collecting jedi>=0.16\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (67.6.1)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (4.8.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (0.1.6)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (0.1.2)\n","Collecting linkify-it-py<3,>=1\n","  Downloading linkify_it_py-2.0.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 7)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 7)) (2022.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 7)) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 7)) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 7)) (1.26.15)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 1)) (1.11.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 1)) (2.0.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 1)) (3.0)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 1)) (16.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 1)) (3.25.2)\n","Collecting starlette<0.27.0,>=0.26.1\n","  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 KB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from httpx->gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (1.3.0)\n","Collecting rfc3986[idna2008]<2,>=1.3\n","  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n","Collecting httpcore<0.17.0,>=0.15.0\n","  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (1.4.4)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (5.12.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (1.0.7)\n","Collecting h11>=0.8\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.9/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx->gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (3.6.2)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (3.15.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython>=7.8.0->black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (0.8.3)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 12)) (0.19.3)\n","Collecting uc-micro-py\n","  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython>=7.8.0->black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.8.0->black->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 5)) (0.2.6)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.4.0->accelerate->-r /content/drive/MyDrive/projects/try-large-models/nlp/try_llama/requirements.txt (line 1)) (1.3.0)\n","Building wheels for collected packages: fire, peft, transformers, ffmpy\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116952 sha256=c22c28bf0d793697dc82e01a9e944026cad2173e091aff17c1f8f54d95c46f53\n","  Stored in directory: /root/.cache/pip/wheels/f7/f1/89/b9ea2bf8f80ec027a88fef1d354b3816b4d3d29530988972f6\n","  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for peft: filename=peft-0.3.0.dev0-py3-none-any.whl size=49037 sha256=faef49f86724fd0e867959ff05d8c931a18c88dbe694eebd1adab2326efddb9e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-wgwvjkr5/wheels/2d/60/1b/0edd9dc0f0c489738b1166bc1b0b560ee368f7721f89d06e3a\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.28.0.dev0-py3-none-any.whl size=6895957 sha256=836de1f0706b0fb84aac6dec24a235556eef91cff547433dede2dd9455d41356\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-wgwvjkr5/wheels/f7/92/8c/752ff3bfcd3439805d8bbf641614da38ef3226e127ebea86ee\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4707 sha256=702e5e7d1289ee1ed152c0dbeed6ee95e156ed244ec30d6462c57cfc7750a759\n","  Stored in directory: /root/.cache/pip/wheels/91/e2/96/f676aa08bfd789328c6576cd0f1fde4a3d686703bb0c247697\n","Successfully built fire peft transformers ffmpy\n","Installing collected packages: tokenizers, sentencepiece, rfc3986, pydub, ffmpy, bitsandbytes, xxhash, websockets, uc-micro-py, tokenize-rt, semantic-version, python-multipart, pathspec, orjson, mypy-extensions, multidict, loralib, jedi, h11, frozenlist, fire, dill, async-timeout, aiofiles, yarl, uvicorn, starlette, responses, multiprocess, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, black, aiosignal, transformers, httpx, gradio-client, fastapi, aiohttp, gradio, datasets, accelerate, peft\n","Successfully installed accelerate-0.18.0 aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 bitsandbytes-0.37.2 black-23.3.0 datasets-2.11.0 dill-0.3.6 fastapi-0.95.0 ffmpy-0.3.0 fire-0.5.0 frozenlist-1.3.3 gradio-3.24.1 gradio-client-0.0.8 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 huggingface-hub-0.13.4 jedi-0.18.2 linkify-it-py-2.0.0 loralib-0.1.1 mdit-py-plugins-0.3.3 multidict-6.0.4 multiprocess-0.70.14 mypy-extensions-1.0.0 orjson-3.8.9 pathspec-0.11.1 peft-0.3.0.dev0 pydub-0.25.1 python-multipart-0.0.6 responses-0.18.0 rfc3986-1.5.0 semantic-version-2.10.0 sentencepiece-0.1.97 starlette-0.26.1 tokenize-rt-5.0.0 tokenizers-0.13.3 transformers-4.28.0.dev0 uc-micro-py-1.0.1 uvicorn-0.21.1 websockets-11.0.1 xxhash-3.2.0 yarl-1.8.2\n"]}]},{"cell_type":"code","source":["\"\"\"\n","https://huggingface.co/blog/how-to-generate\n","\"\"\"\n","import torch\n","from transformers import GPT2LMHeadModel\n","from transformers import GPT2Tokenizer\n","from transformers import GenerationConfig"],"metadata":{"id":"C8Os9cScRFem","executionInfo":{"status":"ok","timestamp":1680930939270,"user_tz":-480,"elapsed":547,"user":{"displayName":"yuncong li","userId":"08224369488617466670"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["model_name = \"gpt2\"\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","# add the EOS token as PAD token to avoid warnings\n","model = GPT2LMHeadModel.from_pretrained(model_name, pad_token_id=tokenizer.eos_token_id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137,"referenced_widgets":["49a990c0470b40e9895eb427e70cbc4f","8ce49e6ab81845a1aed5f31b253f627e","06c75b5a01c94dfd9a614219d03fec25","b223170aab9d475887e218612a07e352","68ccdf4b21d34a3eb9463d422c2af514","c3602892648c4381a20d4e9ee083a08f","0181301fcee74672a7b31c81575f231f","d1f6d2c7761f4a418ccdf5abae5f5931","c70e2a3b00bd4ed1bf5315617687c582","5b5321028d0c496f9747b4e7c943f721","9c2d36db68b343b2a7ab02fa34a7d7e7","accea588eef24b238bf8fb51d02e0785","cb499f976dc04eb48167373ca5cac62b","8155caa6d6484101bc584a7b16805f6f","f7cdf3600cca4a9cad476152b0ff495a","46982cccf6194766a75cd7f89e67547a","03021e20aadc43a3ab5ad12ed2f796b3","ddfa552ae0ef4375b48e3466c654e70d","87d93aacf004431a81037253d76716fb","ce91bd5e5f8c4e0183867d87d6834218","869b42ebfa1846feb2edc997272d8f97","5f8e3099a1dc4d0eaf1ea73b276d1582"]},"id":"eX2VhcnaRbai","executionInfo":{"status":"ok","timestamp":1680930947957,"user_tz":-480,"elapsed":4861,"user":{"displayName":"yuncong li","userId":"08224369488617466670"}},"outputId":"f9b3a9b0-b9c4-4c6c-c1ef-d1eb07d73105"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49a990c0470b40e9895eb427e70cbc4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"accea588eef24b238bf8fb51d02e0785"}},"metadata":{}}]},{"cell_type":"markdown","source":["Greedy Search"],"metadata":{"id":"Jgfw3_KCS0dH"}},{"cell_type":"code","source":["# encode context the generation is conditioned on\n","prompt = 'I enjoy walking with my cute dog'\n","input_ids = tokenizer.encode(prompt, return_tensors='pt')\n","\n","# generate text until the output length (which includes the context length) reaches 50\n","max_new_tokens = 50\n","generation_config = GenerationConfig(\n","            max_new_tokens=max_new_tokens\n","        )\n","greedy_output = model.generate(input_ids, generation_config=generation_config)\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ybbf03WbSxqY","executionInfo":{"status":"ok","timestamp":1680931754904,"user_tz":-480,"elapsed":1347,"user":{"displayName":"yuncong li","userId":"08224369488617466670"}},"outputId":"da2149c5-7e37-4805-fa4b-5da3a3abbc64"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n","\n","I'm not sure if I'll ever be able to walk with my\n"]}]},{"cell_type":"markdown","source":["Beam search"],"metadata":{"id":"Ms3jB5rjVjTZ"}},{"cell_type":"code","source":["# encode context the generation is conditioned on\n","prompt = 'I enjoy walking with my cute dog'\n","input_ids = tokenizer.encode(prompt, return_tensors='pt')\n","\n","# generate text until the output length (which includes the context length) reaches 50\n","max_new_tokens = 50\n","generation_config = GenerationConfig(\n","            max_new_tokens=max_new_tokens,\n","            num_beams=5,\n","            early_stopping=True\n","        )\n","beam_output = model.generate(input_ids, generation_config=generation_config)\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ao0nHQuEVeTL","executionInfo":{"status":"ok","timestamp":1680931889980,"user_tz":-480,"elapsed":2601,"user":{"displayName":"yuncong li","userId":"08224369488617466670"}},"outputId":"ffb4c222-6eb4-4405-a435-9b6e11533ff2"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I'm not sure if I'll ever be able to walk with him again.\n","\n","I'm not sure if I'll ever be able to walk\n"]}]},{"cell_type":"code","source":["# encode context the generation is conditioned on\n","prompt = 'I enjoy walking with my cute dog'\n","input_ids = tokenizer.encode(prompt, return_tensors='pt')\n","\n","# generate text until the output length (which includes the context length) reaches 50\n","max_new_tokens = 50\n","generation_config = GenerationConfig(\n","            max_new_tokens=max_new_tokens,\n","            num_beams=5,\n","            early_stopping=True,\n","            no_repeat_ngram_size=2, \n","        )\n","beam_output = model.generate(input_ids, generation_config=generation_config)\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZJqJaxnRWdUt","executionInfo":{"status":"ok","timestamp":1680931957618,"user_tz":-480,"elapsed":2563,"user":{"displayName":"yuncong li","userId":"08224369488617466670"}},"outputId":"0de25df0-ea39-42f8-95f3-153f561dc263"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's time for me to take a step back and think about it. I\n"]}]},{"cell_type":"code","source":["# encode context the generation is conditioned on\n","prompt = 'I enjoy walking with my cute dog'\n","input_ids = tokenizer.encode(prompt, return_tensors='pt')\n","\n","# generate text until the output length (which includes the context length) reaches 50\n","max_new_tokens = 50\n","generation_config = GenerationConfig(\n","            max_new_tokens=max_new_tokens,\n","            num_beams=5,\n","            early_stopping=True,\n","            no_repeat_ngram_size=2, \n","            num_return_sequences=3, \n","        )\n","beam_outputs = model.generate(input_ids, generation_config=generation_config)\n","\n","print(\"Output:\\n\" + 100 * '-')\n","for i, beam_output in enumerate(beam_outputs):\n","  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zMU8qW-WWu4W","executionInfo":{"status":"ok","timestamp":1680932094660,"user_tz":-480,"elapsed":2651,"user":{"displayName":"yuncong li","userId":"08224369488617466670"}},"outputId":"e431071f-4bc4-430c-8cde-10896d01fe16"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","0: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's time for me to take a step back and think about it. I\n","1: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's time for me to take a step back and think about what I've\n","2: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n","\n","I've been thinking about this for a while now, and I think it's time for me to take a step back and think about my dog.\n"]}]},{"cell_type":"markdown","source":["Sampling"],"metadata":{"id":"2DC_im58XMap"}},{"cell_type":"code","source":["# encode context the generation is conditioned on\n","prompt = 'I enjoy walking with my cute dog'\n","input_ids = tokenizer.encode(prompt, return_tensors='pt')\n","\n","# generate text until the output length (which includes the context length) reaches 50\n","max_new_tokens = 50\n","generation_config = GenerationConfig(\n","            max_new_tokens=max_new_tokens,\n","            do_sample=True, \n","            top_k=0 \n","        )\n","sample_output = model.generate(input_ids, generation_config=generation_config)\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rRPhfFVEXMH0","executionInfo":{"status":"ok","timestamp":1680932314739,"user_tz":-480,"elapsed":813,"user":{"displayName":"yuncong li","userId":"08224369488617466670"}},"outputId":"e80129ab-77a7-4a61-d3c3-89b56db1d9a4"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I enjoy walking with my cute dog and driving Mendelssohn County cars. I also love reading and hearing passing papers. I was lucky to nail Andersen's book Buffet or bark off mod!\n"]}]},{"cell_type":"code","source":["# encode context the generation is conditioned on\n","prompt = 'I enjoy walking with my cute dog'\n","input_ids = tokenizer.encode(prompt, return_tensors='pt')\n","\n","# generate text until the output length (which includes the context length) reaches 50\n","max_new_tokens = 50\n","generation_config = GenerationConfig(\n","            max_new_tokens=max_new_tokens,\n","            do_sample=True, \n","            top_k=0,\n","            temperature=0.7 \n","        )\n","sample_output = model.generate(input_ids, generation_config=generation_config)\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IvmhDEFQYDUH","executionInfo":{"status":"ok","timestamp":1680932390092,"user_tz":-480,"elapsed":1366,"user":{"displayName":"yuncong li","userId":"08224369488617466670"}},"outputId":"15b2fdf1-12d0-4e18-e32b-751a95e93b7d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I enjoy walking with my cute dog. It's so much more fun to be with him. I feel like we should be in and around each other. I know there are a lot of groups out there that don't like dogs, but I'm not one of them. The only\n"]}]},{"cell_type":"markdown","source":["Top-K Sampling"],"metadata":{"id":"hpsy1FQxYVCm"}},{"cell_type":"code","source":["# encode context the generation is conditioned on\n","prompt = 'I enjoy walking with my cute dog'\n","input_ids = tokenizer.encode(prompt, return_tensors='pt')\n","\n","# generate text until the output length (which includes the context length) reaches 50\n","max_new_tokens = 50\n","generation_config = GenerationConfig(\n","            max_new_tokens=max_new_tokens,\n","            do_sample=True, \n","            top_k=50,\n","            temperature=0.7\n","        )\n","sample_output = model.generate(input_ids, generation_config=generation_config)\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"On9SoJk3YX4l","executionInfo":{"status":"ok","timestamp":1680932483456,"user_tz":-480,"elapsed":1232,"user":{"displayName":"yuncong li","userId":"08224369488617466670"}},"outputId":"b78b2ac7-52b9-4ae1-aba3-c5cb6b9539b9"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I enjoy walking with my cute dog, but I am not interested in the world. I often look at the world as a picture. The world is beautiful, but I am not interested in the world. I like to watch the news and see the pictures. I wish I could say\n"]}]},{"cell_type":"markdown","source":["Top-p (nucleus) sampling"],"metadata":{"id":"qOtmB0emYlKY"}},{"cell_type":"code","source":["# encode context the generation is conditioned on\n","prompt = 'I enjoy walking with my cute dog'\n","input_ids = tokenizer.encode(prompt, return_tensors='pt')\n","\n","# generate text until the output length (which includes the context length) reaches 50\n","max_new_tokens = 50\n","generation_config = GenerationConfig(\n","            max_new_tokens=max_new_tokens,\n","            do_sample=True, \n","            top_k=0,\n","            temperature=0.7,\n","            top_p=0.92,\n","        )\n","sample_output = model.generate(input_ids, generation_config=generation_config)\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UY_lgU8cYnse","executionInfo":{"status":"ok","timestamp":1680932534127,"user_tz":-480,"elapsed":2254,"user":{"displayName":"yuncong li","userId":"08224369488617466670"}},"outputId":"1e4766b2-524e-4cad-e88d-1bb9d684f7c4"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I enjoy walking with my cute dog and I love playing with her.\n","\n","\"I am also a fan of the band, but I just can't quite express how much I like them so much.\"\n","\n","Mr Tannen says he has been spending time with the band since\n"]}]},{"cell_type":"code","source":["# encode context the generation is conditioned on\n","prompt = 'I enjoy walking with my cute dog'\n","input_ids = tokenizer.encode(prompt, return_tensors='pt')\n","\n","# generate text until the output length (which includes the context length) reaches 50\n","max_new_tokens = 50\n","generation_config = GenerationConfig(\n","            max_new_tokens=max_new_tokens,\n","            do_sample=True, \n","            top_k=50,\n","            temperature=0.7,\n","            top_p=0.92,\n","        )\n","sample_output = model.generate(input_ids, generation_config=generation_config)\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7J7vgGoAY3NB","executionInfo":{"status":"ok","timestamp":1680932574889,"user_tz":-480,"elapsed":1546,"user":{"displayName":"yuncong li","userId":"08224369488617466670"}},"outputId":"e323b98d-d0b2-4b4d-c3fe-8c5b13ef1043"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I enjoy walking with my cute dog. He is always up for a ride. I want to see him play with my little puppy, and I like to keep him in my home. My little dog is my favorite cat, and he is always smiling when I take him outside. I\n"]}]}]}